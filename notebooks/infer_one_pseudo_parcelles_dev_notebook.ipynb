{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict rasters for a single placettes out of a parcelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Everything is imported\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "import functools\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy.stats import gamma\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchnet as tnt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import gc\n",
    "\n",
    "# from osgeo import gdal, osr  # TODO: UNCOMMENT\n",
    "import torch.nn as nn\n",
    "from scipy.special import digamma, polygamma\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# Weird behavior: loading twice in cell appears to remove an elsewise occuring error.\n",
    "for i in range(2):\n",
    "    try:\n",
    "        matplotlib.use(\"TkAgg\")  # rerun this cell if an error occurs.\n",
    "    except:\n",
    "        print(\"!\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pickle\n",
    "from torch_scatter import scatter_max, scatter_mean\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "np.random.seed(42)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# We import from other files\n",
    "import sys\n",
    "sys.path.append(\"/home/CGaydon/Documents/LIDAR PAC/plot_vegetation_coverage/\")\n",
    "from config import args\n",
    "from model.model import PointNet\n",
    "from utils.useful_functions import *\n",
    "from data_loader.loader import *\n",
    "from utils.load_las_data import *\n",
    "from model.loss_functions import *\n",
    "from model.accuracy import *\n",
    "from em_gamma.get_gamma_parameters_em import *\n",
    "from model.train import train_full\n",
    "\n",
    "print(\"Everything is imported\")\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "np.random.seed(42)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests with Shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Test from https://gis.stackexchange.com/a/192669/184486\n",
    "# import shapely\n",
    "# from shapely.geometry import Point\n",
    "# # idx_center = 0\n",
    "# # disk = Point([15,17]).buffer(10)\n",
    "# # other_point = Point([15,17+9.99999])\n",
    "# # other_point.within(disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16, 26]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Test from https://gis.stackexchange.com/a/327680/184486\n",
    "# from shapely.prepared import prep\n",
    "# from shapely.geometry import asMultiPoint\n",
    "\n",
    "# radius = 10\n",
    "# center = Point([15,17])\n",
    "# prepped_buffer = prep(center.buffer(radius))\n",
    "# two_points = [[16,17+9], [16,17+11]]\n",
    "# points = asMultiPoint(two_points)\n",
    "# # boolean array indicating what points were contained within distance from the line\n",
    "# contained = np.fromiter(map(prepped_buffer.contains, points), np.bool)\n",
    "# # take all rows from all_objs that are within distance from line\n",
    "# contained_points = np.compress(contained, two_points, axis=0)\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Everything is imported\n",
      "False\n",
      "09:37:13\n",
      "Results folder:  /home/CGaydon/Documents/LIDAR PAC/plot_vegetation_coverage/experiments/RESULTS_3_strata/only_stratum/DEV/2021-06-03_11h37m13s/\n",
      "trained model was loaded from /home/CGaydon/Documents/LIDAR PAC/plot_vegetation_coverage/experiments/RESULTS_3_strata/only_stratum/PROD/2021-05-31_11h40m21s/model_ss_4096_dp_32_fold_1.pt\n",
      "Square dimensions are 14.14m*14.14mbut we move 11.02m at a time to have 3.12m of overlap\n",
      "(999, 9)\n",
      "torch.Size([338, 3])\n",
      "(4192, 9)\n",
      "torch.Size([622, 3])\n",
      "(3010, 9)\n",
      "torch.Size([571, 3])\n",
      "(29, 9)\n",
      "torch.Size([28, 3])\n",
      "(2980, 9)\n",
      "torch.Size([502, 3])\n",
      "(6578, 9)\n",
      "torch.Size([666, 3])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-84218df2a99c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcenter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrid_pixel_xy_centers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mcontained_points_nparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_points_within_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_nparray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;31m# infer if non-empty selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontained_points_nparray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/LIDAR PAC/plot_vegetation_coverage/model/infer_utils.py\u001b[0m in \u001b[0;36mextract_points_within_disk\u001b[0;34m(points_nparray, center, radius)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mmultipoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masMultiPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_nparray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# boolean array indicating what points were contained within distance from the line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mcontained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepped_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultipoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;31m# take all rows from all_objs that are within distance from line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mcontained_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_nparray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lidar_pac/lib/python3.9/site-packages/shapely/impl.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             raise ImplementationError(\n",
      "\u001b[0;32m~/anaconda3/envs/lidar_pac/lib/python3.9/site-packages/shapely/prepared.py\u001b[0m in \u001b[0;36mcontains\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__geom__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mdelegated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;34m\"\"\"Returns True if the geometry contains the other, else False\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchnet as tnt\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "\n",
    "# Weird behavior: loading twice in cell appears to remove an elsewise occuring error.\n",
    "for i in range(2):\n",
    "    try:\n",
    "        matplotlib.use(\"TkAgg\")  # rerun this cell if an error occurs.\n",
    "    except:\n",
    "        print(\"!\")\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "np.random.seed(42)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# We import from other files\n",
    "from utils.useful_functions import *\n",
    "from data_loader.loader import *\n",
    "from utils.load_las_data import load_all_las_from_folder, open_metadata_dataframe\n",
    "from model.loss_functions import *\n",
    "from model.accuracy import *\n",
    "from em_gamma.get_gamma_parameters_em import *\n",
    "from model.model import PointNet\n",
    "from utils.point_cloud_classifier import PointCloudClassifier\n",
    "from model.infer_utils import (\n",
    "    divide_parcel_las_and_get_disk_centers,\n",
    "    extract_points_within_disk,\n",
    "    infer_from_single_cloud,\n",
    ")\n",
    "\n",
    "from config import args\n",
    "args.z_max = 24.14  # the TRAINING args should be loaded ! \n",
    "\n",
    "\n",
    "print(\"Everything is imported\")\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "np.random.seed(42)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Create the result folder\n",
    "create_new_experiment_folder(args)  # new paths are added to args\n",
    "las_folder = args.las_parcelles_folder_path\n",
    "las_filenames = os.listdir(las_folder)\n",
    "\n",
    "\n",
    "# define the classifier\n",
    "model = torch.load(args.trained_model_path)\n",
    "print(f\"trained model was loaded from {args.trained_model_path}\")\n",
    "model.eval()\n",
    "# load the model\n",
    "# print(\n",
    "#     \"Total number of parameters: {}\".format(\n",
    "#         sum([p.numel() for p in model.parameters()])\n",
    "#     )\n",
    "# )\n",
    "# print(model)\n",
    "PCC = PointCloudClassifier(args)\n",
    "\n",
    "for las_filename in las_filenames:\n",
    "    if args.mode == \"DEV\":\n",
    "        if las_filename != \"004000715-5-18.las\":\n",
    "            continue\n",
    "    # her we divide all parcels into plots\n",
    "    grid_pixel_xy_centers, points_nparray = divide_parcel_las_and_get_disk_centers(\n",
    "        args, las_folder, las_filename, save_fig_of_division=True\n",
    "    )\n",
    "\n",
    "    # TODO: replace this loop by an ad-hoc DataLoader\n",
    "\n",
    "    for center in grid_pixel_xy_centers:\n",
    "        contained_points_nparray = extract_points_within_disk(points_nparray, center)\n",
    "        # infer if non-empty selection\n",
    "        if contained_points_nparray.shape[0] > 0:\n",
    "            print(contained_points_nparray.shape)\n",
    "            contained_points_nparray = contained_points_nparray.transpose()\n",
    "            contained_points_nparray = normalize_cloud_data(contained_points_nparray, args)\n",
    "            # add a batch dim before trying out dataloader\n",
    "            contained_points_nparray = np.expand_dims(contained_points_nparray, axis=0)\n",
    "            contained_points_tensor = torch.from_numpy(contained_points_nparray)\n",
    "\n",
    "            pred_pixels = infer_from_single_cloud(\n",
    "                model, PCC, contained_points_tensor, args\n",
    "            )\n",
    "#             print(pred_pixels.shape) # pixels from within the plot area only !\n",
    "            \n",
    "\n",
    "    # contained_points_nparray\n",
    "    # generate the train and test dataset\n",
    "    # eval_set = tnt.dataset.ListDataset(\n",
    "    #     test_list,\n",
    "    #     functools.partial(\n",
    "    #         cloud_loader,\n",
    "    #         dataset=nparray_clouds_dict,\n",
    "    #         df_gt=df_gt,\n",
    "    #         train=False,\n",
    "    #         args=args,\n",
    "    #     ),\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256000000,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ok for 10km*10km\n",
    "np.random.random((int(10000/0.625)**2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([666, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "911575.74"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
