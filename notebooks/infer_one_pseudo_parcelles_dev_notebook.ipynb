{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict rasters for a single placettes out of a parcelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Dataset folder in use: /home/CGaydon/Documents/LIDAR PAC/plot_vegetation_coverage/data/\n",
      "Arguments were imported in DEV mode\n",
      "Everything is imported\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "import functools\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy.stats import gamma\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchnet as tnt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import gc\n",
    "\n",
    "# from osgeo import gdal, osr  # TODO: UNCOMMENT\n",
    "import torch.nn as nn\n",
    "from scipy.special import digamma, polygamma\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# Weird behavior: loading twice in cell appears to remove an elsewise occuring error.\n",
    "for i in range(2):\n",
    "    try:\n",
    "        matplotlib.use(\"TkAgg\")  # rerun this cell if an error occurs.\n",
    "    except:\n",
    "        print(\"!\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pickle\n",
    "from torch_scatter import scatter_max, scatter_mean\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "np.random.seed(42)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# We import from other files\n",
    "import sys\n",
    "sys.path.append(\"/home/CGaydon/Documents/LIDAR PAC/plot_vegetation_coverage/\")\n",
    "from config import args\n",
    "from model.model import PointNet\n",
    "from utils.useful_functions import *\n",
    "from data_loader.loader import *\n",
    "from utils.load_las_data import *\n",
    "from model.loss_functions import *\n",
    "from model.accuracy import *\n",
    "from em_gamma.get_gamma_parameters_em import *\n",
    "from model.train import train_full\n",
    "\n",
    "print(\"Everything is imported\")\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "np.random.seed(42)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests with Shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test from https://gis.stackexchange.com/a/192669/184486\n",
    "# import shapely\n",
    "# from shapely.geometry import Point\n",
    "# # idx_center = 0\n",
    "# # disk = Point([15,17]).buffer(10)\n",
    "# # other_point = Point([15,17+9.99999])\n",
    "# # other_point.within(disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test from https://gis.stackexchange.com/a/327680/184486\n",
    "# from shapely.prepared import prep\n",
    "# from shapely.geometry import asMultiPoint\n",
    "\n",
    "# radius = 10\n",
    "# center = Point([15,17])\n",
    "# prepped_buffer = prep(center.buffer(radius))\n",
    "# two_points = [[16,17+9], [16,17+11]]\n",
    "# points = asMultiPoint(two_points)\n",
    "# # boolean array indicating what points were contained within distance from the line\n",
    "# contained = np.fromiter(map(prepped_buffer.contains, points), np.bool)\n",
    "# # take all rows from all_objs that are within distance from line\n",
    "# contained_points = np.compress(contained, two_points, axis=0)\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Everything is imported\n",
      "False\n",
      "14:31:38\n",
      "Results folder:  /home/CGaydon/Documents/LIDAR PAC/plot_vegetation_coverage/experiments/RESULTS_3_strata/only_stratum/DEV/inference/2021-06-03_16h31m38s/\n",
      "trained model was loaded from /home/CGaydon/Documents/LIDAR PAC/plot_vegetation_coverage/experiments/RESULTS_3_strata/only_stratum/PROD/2021-05-31_11h40m21s/model_ss_4096_dp_32_fold_1.pt\n",
      "Square dimensions are 14.14m*14.14mbut we move 11.02m at a time to have 3.12m of overlap\n",
      "(999, 9)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 1]' is invalid for input of size 999",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-917dfc3d3cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# pred_pointwise was permuted from (scores_nb, pts_nb) to (pts_nb, scores_nb) for some reasons at the end of PCC.run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mpred_pointwise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_pointwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             create_geotiff_raster(\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mpred_pointwise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/LIDAR PAC/plot_vegetation_coverage/model/infer_utils.py\u001b[0m in \u001b[0;36mcreate_geotiff_raster\u001b[0;34m(args, pred_pointwise, current_cloud, plot_center, plot_name, add_weights_band)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;34m\"\"\" \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;31m# we do raster reprojection, but we do not use torch scatter as we have to associate each value to a pixel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     image_low_veg, image_med_veg, image_high_veg = infer_and_project_on_rasters(\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0mcurrent_cloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_pointwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     )\n",
      "\u001b[0;32m~/Documents/LIDAR PAC/plot_vegetation_coverage/utils/create_final_images.py\u001b[0m in \u001b[0;36minfer_and_project_on_rasters\u001b[0;34m(current_cloud, args, pred_cloud)\u001b[0m\n\u001b[1;32m    388\u001b[0m     xy = current_cloud[\n\u001b[1;32m    389\u001b[0m         \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m     ]  # Careful to this batch dimenison that may go away at some point !\n\u001b[0m\u001b[1;32m    391\u001b[0m     xy = torch.floor(\n\u001b[1;32m    392\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 1]' is invalid for input of size 999"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchnet as tnt\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "\n",
    "# Weird behavior: loading twice in cell appears to remove an elsewise occuring error.\n",
    "for i in range(2):\n",
    "    try:\n",
    "        matplotlib.use(\"TkAgg\")  # rerun this cell if an error occurs.\n",
    "    except:\n",
    "        print(\"!\")\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "np.random.seed(42)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# We import from other files\n",
    "from utils.useful_functions import *\n",
    "from data_loader.loader import *\n",
    "from utils.load_las_data import load_all_las_from_folder, open_metadata_dataframe\n",
    "from model.loss_functions import *\n",
    "from model.accuracy import *\n",
    "from em_gamma.get_gamma_parameters_em import *\n",
    "from model.model import PointNet\n",
    "from utils.point_cloud_classifier import PointCloudClassifier\n",
    "from model.infer_utils import (\n",
    "    divide_parcel_las_and_get_disk_centers,\n",
    "    extract_points_within_disk,\n",
    "    create_geotiff_raster,\n",
    ")\n",
    "from utils.reproject_to_2d_and_predict_plot_coverage import project_to_2d\n",
    "\n",
    "\n",
    "from config import args\n",
    "\n",
    "args.z_max = 24.14  # the TRAINING args should be loaded !\n",
    "\n",
    "\n",
    "print(\"Everything is imported\")\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "np.random.seed(42)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Create the result folder\n",
    "create_new_experiment_folder(args, infer_mode=True)  # new paths are added to args\n",
    "las_folder = args.las_parcelles_folder_path\n",
    "las_filenames = os.listdir(las_folder)\n",
    "\n",
    "\n",
    "# define the classifier\n",
    "model = torch.load(args.trained_model_path)\n",
    "print(f\"trained model was loaded from {args.trained_model_path}\")\n",
    "model.eval()\n",
    "# load the model\n",
    "# print(\n",
    "#     \"Total number of parameters: {}\".format(\n",
    "#         sum([p.numel() for p in model.parameters()])\n",
    "#     )\n",
    "# )\n",
    "# print(model)\n",
    "PCC = PointCloudClassifier(args)\n",
    "\n",
    "for las_filename in las_filenames:\n",
    "    if args.mode == \"DEV\":\n",
    "        if las_filename != \"004000715-5-18.las\":\n",
    "            continue\n",
    "    # her we divide all parcels into plots\n",
    "    grid_pixel_xy_centers, points_nparray = divide_parcel_las_and_get_disk_centers(\n",
    "        args, las_folder, las_filename, save_fig_of_division=True\n",
    "    )\n",
    "\n",
    "    # TODO: replace this loop by an ad-hoc DataLoader\n",
    "\n",
    "    for plot_center in grid_pixel_xy_centers:\n",
    "        contained_points_nparray = extract_points_within_disk(\n",
    "            points_nparray, plot_center\n",
    "        )\n",
    "        # infer if non-empty selection\n",
    "        if contained_points_nparray.shape[0] > 0:\n",
    "            las_id = las_filename.split(\".\")[0]\n",
    "\n",
    "            # TODO: remove print\n",
    "            print(contained_points_nparray.shape)\n",
    "            contained_points_nparray = contained_points_nparray.transpose()\n",
    "            contained_points_nparray = normalize_cloud_data(\n",
    "                contained_points_nparray, args\n",
    "            )\n",
    "\n",
    "            # add a batch dim before trying out dataloader\n",
    "            contained_points_nparray = np.expand_dims(contained_points_nparray, axis=0)\n",
    "            contained_points_tensor = torch.from_numpy(contained_points_nparray)\n",
    "\n",
    "            # infer\n",
    "            model.eval()\n",
    "            # compute pointwise prediction\n",
    "            pred_pointwise, _ = PCC.run(model, contained_points_tensor)\n",
    "\n",
    "            # pred_pointwise was permuted from (scores_nb, pts_nb) to (pts_nb, scores_nb) for some reasons at the end of PCC.run\n",
    "            pred_pointwise = pred_pointwise.permute(1, 0)\n",
    "            create_geotiff_raster(\n",
    "                args,\n",
    "                pred_pointwise,\n",
    "                contained_points_tensor,\n",
    "                plot_center,\n",
    "                las_id,\n",
    "                add_weights_band=False,\n",
    "            )\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "911575.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
